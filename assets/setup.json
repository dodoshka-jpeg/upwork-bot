{
  "rss_channel": "",
  "rss_url": [
    {
      "name": "data_scraping",
      "url": "https://www.upwork.com/ab/feed/jobs/rss?q=data+scraping&proposals=0-4&verified_payment_only=1&sort=recency&paging=0%3B10&api_params=1&securityToken=d3be0a318e8be17e5d3634085f447146882ecb123bb15731085cec48fb1fe38d436ef74454fabeb1e753426459580e7e471d87e2d140a32ba1e659ae7b5bfe71&userUid=1678435651088986112&orgUid=1678435651088986113",
      "last_feed": [
        {
          "title": "Auto population of Social Media info through API (+Scraping) - Upwork",
          "description": "We are in wordpress.<br /><br />\nWe have some fields with basic info of some social media profile urls<br />\neg. followers, engagement etc (Instagram, Tik Tok, Facebook, Pinterest , Twitch, Youtube, Twitter)<br /><br />\nNow these data are entered manually.<br /><br />\nWe need to automate data extraction and fields population through APIs when possible and scraping when not possible.<br /><br /><b>Budget</b>: $200\n<br /><b>Posted On</b>: October 03, 2023 15:55 UTC<br /><b>Category</b>: Data Extraction<br /><b>Skills</b>:API Integration,     Automation,     Data Extraction,     Database    \n<br /><b>Skills</b>:        API Integration,                     Automation,                     Data Extraction,                     Database            <br /><b>Country</b>: Italy\n<br /><a href=\"https://www.upwork.com/jobs/Auto-population-Social-Media-info-through-API-Scraping_%7E01632cad5ec7a1b965?source=rss\">click to apply</a>\n",
          "link": "https://www.upwork.com/jobs/Auto-population-Social-Media-info-through-API-Scraping_%7E01632cad5ec7a1b965?source=rss"
        },
        {
          "title": "Looking for Amazon US sellers database - Upwork",
          "description": "I am looking for genuine Amazon US sellers data. This data should include store name, store link, feedback and star ratings, store address and seller contact details such as email id and phone number.<br />\nSeller should be active and stores with 60+ feedback ratings are required.<br />\nIf anyone has readily data available it is good. I will pay $20 for 2000 Amazon US sellers data.<br /><br /><b>Budget</b>: $20\n<br /><b>Posted On</b>: October 03, 2023 14:41 UTC<br /><b>Category</b>: Data Extraction<br /><b>Skills</b>:Lead Generation,     Data Scraping,     Data Entry,     Microsoft Excel    \n<br /><b>Skills</b>:        Lead Generation,                     Data Scraping,                     Data Entry,                     Microsoft Excel            <br /><b>Country</b>: India\n<br /><a href=\"https://www.upwork.com/jobs/Looking-for-Amazon-sellers-database_%7E01405848c3a7995130?source=rss\">click to apply</a>\n",
          "link": "https://www.upwork.com/jobs/Looking-for-Amazon-sellers-database_%7E01405848c3a7995130?source=rss"
        },
        {
          "title": "Urgent Assistance Needed - Data Scraping and Google Cloud Expert - Upwork",
          "description": "Urgent: Need developer to fix SEC Edgar Latest filings scraper<br /><br />\nWe hired a freelancer on Upwork to complete this project for us and everything was working well until the data suddenly stopped updating. We&#039;ve been reaching out to the developer for the past 3 weeks but haven&#039;t received a response. We have all the coding and a video overview of the code from the developer, but we are not technically savvy enough to troubleshoot the issue on our own. We now need urgent help to bring our data back online.<br /><br />\nWe need help to get the scraper back online as soon as possible.<br /><br />\nBelow is a high-level overview of the data scraping script:<br />\n1. The script scrapes the US SEC Edgar Latest filings website<br />\n2. The script then stores the scraped data into a Postgres database hosted on Google Cloud.<br />\n3. The script runs indefinitely, continuously scraping and storing new data.<br />\n4. Last step data is to Connect Excel to PostgreSQL Database table which stop updated<br /><br />\nIf you have expertise in Python, web scraping, Postgres, and Google Cloud, and you&#039;re available to help us urgently, please reach out. Your ability to work with our existing code and your commitment to getting our project back on track are highly valued.<br /><br /><b>Budget</b>: $20\n<br /><b>Posted On</b>: October 03, 2023 14:21 UTC<br /><b>Category</b>: Scripting &amp; Automation<br /><b>Skills</b>:API Integration,     Scripting,     Automation,     Python,     Data Entry,     Microsoft Excel,     Data Scraping,     Google Cloud Platform,     Google Cloud Vision API,     SQL    \n<br /><b>Skills</b>:        API Integration,                     Scripting,                     Automation,                     Python,                     Data Entry,                     Microsoft Excel,                     Data Scraping,                     Google Cloud Platform,                     Google Cloud Vision API,                     SQL            <br /><b>Country</b>: United States\n<br /><a href=\"https://www.upwork.com/jobs/Urgent-Assistance-Needed-Data-Scraping-and-Google-Cloud-Expert_%7E01606cc60f479de920?source=rss\">click to apply</a>\n",
          "link": "https://www.upwork.com/jobs/Urgent-Assistance-Needed-Data-Scraping-and-Google-Cloud-Expert_%7E01606cc60f479de920?source=rss"
        },
        {
          "title": "Web scraping script using crawlee and node - Upwork",
          "description": "Description of work:<br /><br />\nI want to use scraping to get information from a few urls, and want to make sure the scraping is scripted, such that I can repeat the scraping later.<br />\nYou should know about scraping, node, and crawlee&nbsp;&nbsp;(https://crawlee.dev/).<br /><br />\nAs a deliverable, I need a README and javascript files to do the<br />\nscraping myself.&nbsp;&nbsp;Your task is to write the scripts as described below.<br /><br />\nI will test the scripts and give some feedback/questions, and expect<br />\nyou to address this.<br /><br />\nThe following is a description of the things to do and the requirements.<br />\n - Use crawlee to write a crawler/scraper with 2 options and save output of both:<br />\n&nbsp;&nbsp;&nbsp;- cheerio https://crawlee.dev/api/cheerio-crawler/class/CheerioCrawler<br />\n&nbsp;&nbsp;&nbsp;- playwright https://crawlee.dev/api/playwright-crawler/class/PlaywrightCrawler<br />\n - Write code with ES6 javascript using import statements, NO typescript<br />\n - Export the cralwer/scraper, such that I can call with the following interface:<br />\n&nbsp;&nbsp;&nbsp;: import&nbsp;&nbsp;genscraper&nbsp;&nbsp;from &#039;./genscraper.js&#039;;<br />\n&nbsp;&nbsp;&nbsp;: genscraper(&#039;url here&#039;,&#039;options=options object); returns json<br />\n&nbsp;&nbsp;&nbsp;then save json in file named like: &amp;quot;20231003T104556Z-www.url.com--path--path&amp;quot;<br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(date + utc time when crawl started + url);<br />\n - use this pattern to scrape the following urls:<br />\n&nbsp;&nbsp;&nbsp;- 5 - 10 urls, these will be provided later, these are public urls<br />\n - From each url, extract:<br />\n&nbsp;&nbsp;&nbsp;- body text in html<br />\n&nbsp;&nbsp;&nbsp;- body text in plain text<br />\n&nbsp;&nbsp;&nbsp;- name of the addon<br />\n&nbsp;&nbsp;&nbsp;- vendor of the addon<br />\n&nbsp;&nbsp;&nbsp;- count number of images, and get their captions/titles and links<br />\n&nbsp;&nbsp;&nbsp;- get all links<br />\n - export the data as json, with the html and the html converted to<br />\n&nbsp;&nbsp;&nbsp;plain text<br />\n&nbsp;&nbsp;&nbsp;- https://www.npmjs.com/package/html-to-text to get plain text<br />\n - also save scraped url<br />\n - need a script such that you can crawl again e.g. after one month<br />\n - no proxies needed<br />\n - write README on how to use<br />\n - put code into git<br /><br />\nThe javascript snippets in this post are a bit mangled, because no curly braces are allowed in a job post.<br /><br /><b>Budget</b>: $100\n<br /><b>Posted On</b>: October 03, 2023 12:25 UTC<br /><b>Category</b>: Scripting &amp; Automation<br /><b>Skills</b>:Web Crawling,     Data Scraping,     Node.js,     JavaScript    \n<br /><b>Skills</b>:        Web Crawling,                     Data Scraping,                     Node.js,                     JavaScript            <br /><b>Country</b>: Netherlands\n<br /><a href=\"https://www.upwork.com/jobs/Web-scraping-script-using-crawlee-and-node_%7E019ffa742e5e42a51f?source=rss\">click to apply</a>\n",
          "link": "https://www.upwork.com/jobs/Web-scraping-script-using-crawlee-and-node_%7E019ffa742e5e42a51f?source=rss"
        },
        {
          "title": "WhatsApp Export, Extraction and Search (GDrive, Export &amp; Transfer) - Upwork",
          "description": "Hello, <br /><br />\nPLEASE only reply if you have solved for these problems. <br /><br />\nWe are looking to build a solution that allows users to export their WhatsApp messages to their PC (via Google Drive and PC connect). <br /><br />\nHere are some research examples but they don&#039;t solve all the problems. https://github.com/limontec/WhatsApp-GDrive-Downloader<br />\nhttps://github.com/ludufre/wa-explorer<br />\nhttps://jimzrt.github.io/Chatreader3000/<br />\nhttps://github.com/ShaunLWM/node-whatsapp-drive-extractor<br /><br />\nWe want to build a simple lightweight solution that does the following - this has to be as automated as possible: <br />\n- Export backup to GDrive from Android and iOS, download to PC, extract , sort and search<br />\n- Transfer directly from phone to PC when phone is connected; extract , sort and search<br />\n- Export from phone to PC when phone phone is connected ; extract , sort and search<br /><br />\nThank you<br /><br /><b>Budget</b>: $500\n<br /><b>Posted On</b>: October 03, 2023 12:23 UTC<br /><b>Category</b>: Full Stack Development<br /><b>Skills</b>:Data Mining,     Data Extraction,     Search Engine,     Research &amp; Development    \n<br /><b>Skills</b>:        Data Mining,                     Data Extraction,                     Search Engine,                     Research &amp; Development            <br /><b>Country</b>: Germany\n<br /><a href=\"https://www.upwork.com/jobs/WhatsApp-Export-Extraction-and-Search-GDrive-Export-amp-Transfer_%7E01e1f16996f771b8f2?source=rss\">click to apply</a>\n",
          "link": "https://www.upwork.com/jobs/WhatsApp-Export-Extraction-and-Search-GDrive-Export-amp-Transfer_%7E01e1f16996f771b8f2?source=rss"
        },
        {
          "title": "Car Purchasing Lead Generation - Upwork",
          "description": "I am an auto broker (middleman between the client and dealership to get deals done). I am looking for a lead generation expert who has experience in the automotive industry generating leads for dealerships using their own tools to find leads. I need to be able to get high quality leads such as individuals who are ready to buy and are pre qualified before I speak to them. I will ignore everyone who does not mention the words &ldquo;Lead Generation Expert&rdquo; when they message me. No copy and paste templates. <br /><br /><br /><b>Posted On</b>: October 03, 2023 10:58 UTC<br /><b>Category</b>: Lead Generation<br /><b>Skills</b>:Automotive,     Lead Generation,     Prospect List,     Market Research,     Data Scraping    \n<br /><b>Skills</b>:        Automotive,                     Lead Generation,                     Prospect List,                     Market Research,                     Data Scraping            <br /><b>Location Requirement</b>: Only freelancers located in the United States may apply.\n<br /><b>Country</b>: United States\n<br /><a href=\"https://www.upwork.com/jobs/Car-Purchasing-Lead-Generation_%7E01d04bb83c2d8c8372?source=rss\">click to apply</a>\n",
          "link": "https://www.upwork.com/jobs/Car-Purchasing-Lead-Generation_%7E01d04bb83c2d8c8372?source=rss"
        },
        {
          "title": "Browser script for filtering social network profiles - Upwork",
          "description": "Looking for someone to write a script for filtering profiles in the social network FetLife.com like the non-working public script 469501 on sleazyfork.org that is usable cross-browser by extensions like Tampermonkey.<br />\nFixing the existing script and making it work again would also be an option. Please beware that FetLife may block suspicious profiles, so the script must not be detectable by the platform.<br />\nPrimarily, I&#039;m looking for these functions:<br />\n- Sort profiles in the groups and places category by last activity, age, gender, orientation, role, photos and join date.<br />\n- Filter profiles by last activity, age, gender, orientation, role, photos and join date.<br />\n- Find out who recently moved to a specific location (can be derived from the activity log in a profile) and apply filters as above.<br />\n- Search for keywords in profiles.<br /><br /><b>Budget</b>: $100\n<br /><b>Posted On</b>: October 03, 2023 10:01 UTC<br /><b>Category</b>: Scripting &amp; Automation<br /><b>Skills</b>:JavaScript,     HTML,     Python    \n<br /><b>Skills</b>:        JavaScript,                     HTML,                     Python            <br /><b>Country</b>: Germany\n<br /><a href=\"https://www.upwork.com/jobs/Browser-script-for-filtering-social-network-profiles_%7E01aeb925f4b68e6208?source=rss\">click to apply</a>\n",
          "link": "https://www.upwork.com/jobs/Browser-script-for-filtering-social-network-profiles_%7E01aeb925f4b68e6208?source=rss"
        },
        {
          "title": "I want you to create and work on a reddit bot (Undetectable browser automation) - Upwork",
          "description": "Hello there<br /><br />\nI want you to create a tool/bot for me which will read data from&nbsp;&nbsp;excel file and do reddit posting accordingly. The automation will have to be through anonymous browsers like adspower/multilogin/similar anti detect browsers.<br /><br />\nHas to be very stable<br /><br />\nThe tool will always be upgraded so consider it a long term task. You will keep getting tasks. Not looking for an expensive end worker here.<br /><br />\nYou will earn enough but eventually. Also please do not apply with a saved template. I want you to read and apply with a related message so i understand you better.<br /><br />\nThanks<br /><br /><b>Budget</b>: $500\n<br /><b>Posted On</b>: October 03, 2023 05:39 UTC<br /><b>Category</b>: Scripting &amp; Automation<br /><b>Skills</b>:Automation,     Python,     Bot Development,     Selenium,     Data Scraping,     Scripting    \n<br /><b>Skills</b>:        Automation,                     Python,                     Bot Development,                     Selenium,                     Data Scraping,                     Scripting            <br /><b>Country</b>: Bangladesh\n<br /><a href=\"https://www.upwork.com/jobs/want-you-create-and-work-reddit-bot-Undetectable-browser-automation_%7E01192e5cd652e880c2?source=rss\">click to apply</a>\n",
          "link": "https://www.upwork.com/jobs/want-you-create-and-work-reddit-bot-Undetectable-browser-automation_%7E01192e5cd652e880c2?source=rss"
        },
        {
          "title": "Mirco-influencers Outreach (5 valid Youtube videos) - Upwork",
          "description": "Youtube Mirco-influencers Outreach (5 valid videos)<br /><br />\nLong-term project will be considered if your work performance with influencers is excellent and provide us with desired deliverable.&nbsp;&nbsp;<br /><br />\nTarget Mirco-influencers: <br />\n1. Video of showing their own iPhone 15 Pro Max or iPhone 15 Pro on Youtube<br />\n2. at least 300 subscribers, max 50K subscribers<br />\n3. at least 10,000 views on that video<br /><br />\nTasks:<br />\n1. Outreach them by email<br />\n2. Send them our Phone case product<br />\n3. Ask them to make video on Youtube showing our products with their iPhone<br />\n4. Follow-up emails<br />\n5. Create Google Excel to record all the details<br />\n6. Handle all influencers&#039; enquiry &amp;amp; feedback<br /><br />\nTotal: 10 valid videos on Youtube <br /><br /><br /><br />\n*You will have 3 weeks to complete this task, after that please allow 2 weeks for our team to proceed with it<br /><br /><b>Budget</b>: $10\n<br /><b>Posted On</b>: October 03, 2023 03:58 UTC<br /><b>Category</b>: Social Media Marketing<br /><b>Skills</b>:YouTube,     Lead Generation,     Market Research,     List Building,     Data Scraping,     Influencer Marketing,     Social Media Marketing,     Social Media Management    \n<br /><b>Skills</b>:        YouTube,                     Lead Generation,                     Market Research,                     List Building,                     Data Scraping,                     Influencer Marketing,                     Social Media Marketing,                     Social Media Management            <br /><b>Country</b>: Hong Kong\n<br /><a href=\"https://www.upwork.com/jobs/Mirco-influencers-Outreach-valid-Youtube-videos_%7E01976f1e9ddab80e91?source=rss\">click to apply</a>\n",
          "link": "https://www.upwork.com/jobs/Mirco-influencers-Outreach-valid-Youtube-videos_%7E01976f1e9ddab80e91?source=rss"
        },
        {
          "title": "Python - open source contributor - Upwork",
          "description": "Need some people/studen<br />\nfor open source package contribution in python:<br /><br />\nlogging,&nbsp;&nbsp;file IO<br /><br /><br />\npackage is this one:<br />\nhttps://www.pepy.tech/projects/utilmy<br /><br /><br /><br />\nGood to have 5 stars quickly.<br /><br /><br /><br /><b>Budget</b>: $40\n<br /><b>Posted On</b>: October 03, 2023 03:31 UTC<br /><b>Category</b>: Full Stack Development<br /><b>Skills</b>:Python,     Python Script,     JavaScript,     Data Scraping,     Scrapy,     pandas    \n<br /><b>Skills</b>:        Python,                     Python Script,                     JavaScript,                     Data Scraping,                     Scrapy,                     pandas            <br /><b>Country</b>: Japan\n<br /><a href=\"https://www.upwork.com/jobs/Python-open-source-contributor_%7E011c071854dea37cfe?source=rss\">click to apply</a>\n",
          "link": "https://www.upwork.com/jobs/Python-open-source-contributor_%7E011c071854dea37cfe?source=rss"
        }
      ]
    },
    {
      "name": "hehe",
      "url": "asdasd",
      "last_feed": []
    },
    {
      "name": "hihi",
      "url": "123qwekjeljn",
      "last_feed": []
    }
  ]
}